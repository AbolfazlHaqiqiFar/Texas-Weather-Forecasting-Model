{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79140769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import geopandas as gpd\n",
    "import s3fs\n",
    "import zarr\n",
    "import dask \n",
    "import dask.array\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "from shapely.prepared import prep\n",
    "import rioxarray\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a80c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "Start_date = 2013\n",
    "End_date = 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dfb39d",
   "metadata": {},
   "source": [
    "# Task 1 : Download the Texas shape file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5c4cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www2.census.gov/geo/tiger/GENZ2023/shp/cb_2023_us_state_5m.zip\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
    "        z.extractall(\"path_to_extract\")  # م\n",
    "\n",
    "# بارگذاری فایل‌های استخراج شده\n",
    "shapefile_path = \"path_to_extract/cb_2023_us_state_5m.shp\"\n",
    "all_states = gpd.read_file(shapefile_path)\n",
    "texas_shape = all_states[all_states['NAME'] == 'Texas'].to_crs('EPSG:4326')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529d1e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(12, 10))\n",
    "# texas_shape.plot(edgecolor='blue', facecolor='blue', alpha=0.3)\n",
    "# plt.grid(True)\n",
    "# plt.title(\"Texas Shape from US Census Bureau\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabc619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_url = 'noaa-nws-aorc-v1-1-1km' \n",
    "dataset_years = list(range(Start_date, End_date))\n",
    "s3_out = s3fs.S3FileSystem(anon=True)\n",
    "#store = s3fs.S3Map(root=f\"{base_url}/{year}.zarr\", s3=s3_out, check=False)\n",
    "\n",
    "store = [s3fs.S3Map(\n",
    "            root=f\"noaa-nws-aorc-v1-1-1km/{dataset_year}.zarr\",\n",
    "            s3=s3fs.S3FileSystem(anon=True),\n",
    "            check=False\n",
    "        ) for dataset_year in dataset_years]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95fa2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'noaa-nws-aorc-v1-1-1km'\n",
    "s3_out = s3fs.S3FileSystem(anon=True)\n",
    "\n",
    "texas_bbox = texas_shape.bounds\n",
    "minx, miny, maxx, maxy = texas_bbox.iloc[0]\n",
    "\n",
    "print(f\"Texas bounding box: {minx}, {miny}, {maxx}, {maxy}\")\n",
    "\n",
    "available_years = []\n",
    "for year in range(Start_date, End_date):\n",
    "    if s3_out.exists(f\"{base_url}/{year}.zarr\"):\n",
    "        available_years.append(year)\n",
    "\n",
    "print(f\"Available years: {available_years}\")\n",
    "texas_datasets = []\n",
    "\n",
    "for year in available_years:\n",
    "    print(f\"\\nProcessing year: {year}\")\n",
    "    \n",
    "    try:\n",
    "        store = s3fs.S3Map(root=f\"{base_url}/{year}.zarr\", s3=s3_out, check=False)\n",
    "        ds = xr.open_dataset(store, engine='zarr', chunks={'time': 720}) \n",
    "        lat_values = ds.latitude.values\n",
    "        if lat_values[0] > lat_values[-1]:\n",
    "            ds_texas_bbox = ds.sel(latitude=slice(maxy + 1, miny - 1))\n",
    "\n",
    "        ds_texas_bbox = ds.sel(\n",
    "            longitude=slice(minx - 1, maxx + 1),\n",
    "            latitude=slice(miny - 1, maxy + 1)\n",
    "        )\n",
    "\n",
    "        \n",
    "        ds_texas_bbox = ds_texas_bbox.rio.write_crs(\"EPSG:4326\")\n",
    "        ds_texas = ds_texas_bbox.rio.clip(texas_shape.geometry, drop=True)\n",
    "        texas_datasets.append(ds_texas)  \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing year {year}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81191da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_texas_bbox = ds_texas_bbox.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
    "if texas_shape.crs != ds_texas_bbox.rio.crs:\n",
    "    texas_shape = texas_shape.to_crs(ds_texas_bbox.rio.crs)\n",
    "\n",
    "ds_texas = ds_texas_bbox.rio.clip(texas_shape.geometry, drop=True)\n",
    "print(\"After clip:\", ds_texas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe4a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_texas = ds_texas.chunk({'latitude': 200, 'longitude': 200, 'time': 720})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c643f0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure latitude is ascending after clip\n",
    "if ds_texas.latitude.values[0] > ds_texas.latitude.values[-1]:\n",
    "    ds_texas = ds_texas.sortby('latitude')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba217a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_texas = xr.concat(texas_datasets, dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b71237d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_timestep = ds_texas['TMP_2maboveground'].isel(time=0)\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(12, 10))\n",
    "# ax.set_title(f'Plot WITHOUT Cartopy Features', fontsize=16)\n",
    "# single_timestep.plot(ax=ax, cmap='coolwarm', add_colorbar=False)\n",
    "# texas_shape.plot(ax=ax, facecolor='none', edgecolor='black', linewidth=2)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f421ea9f",
   "metadata": {},
   "source": [
    "## Task 2: Label grids by numbering them from 1 to ~700,000. You should start from top left of Texas to bottom right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcebfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with dask.config.set(array_slicing={\"split_large_chunks\": False}):\n",
    "    stacked_ds = ds_texas.stack(grid=(\"latitude\", \"longitude\"))\n",
    "\n",
    "num_grids = stacked_ds.grid.size\n",
    "print(f\"Total number of grids (before masking): {num_grids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eaf378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import points\n",
    "\n",
    "nrows, ncols = len(ds_texas.latitude), len(ds_texas.longitude)\n",
    "grid_labels = np.arange(1, num_grids + 1)\n",
    "labels_2d = grid_labels.reshape((nrows, ncols))\n",
    "\n",
    "# Fix latitude orientation\n",
    "lat_ascending = (ds_texas.latitude.values[1] > ds_texas.latitude.values[0])\n",
    "if lat_ascending:\n",
    "    labels_2d = np.flipud(labels_2d)\n",
    "\n",
    "label_da = xr.DataArray(\n",
    "    labels_2d,\n",
    "    coords={\"latitude\": ds_texas.latitude, \"longitude\": ds_texas.longitude},\n",
    "    dims=[\"latitude\", \"longitude\"]\n",
    ")\n",
    "\n",
    "# Use union_all instead of unary_union\n",
    "texas_geom = texas_shape.union_all()\n",
    "texas_geom_prep = prep(texas_geom)\n",
    "\n",
    "# Vectorized shapely evaluation (MUCH faster)\n",
    "lon, lat = np.meshgrid(ds_texas.longitude.values, ds_texas.latitude.values)\n",
    "pts = points(lon.ravel(), lat.ravel())                 # Vectorized point creation\n",
    "mask_flat = np.array([texas_geom_prep.contains(p) for p in pts])\n",
    "mask = mask_flat.reshape(lon.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967308f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_labels = label_da.where(mask)\n",
    "num_valid_grids = int(masked_labels.notnull().sum().values)\n",
    "print(f\"Number of grid cells inside Texas (after masking): {num_valid_grids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecca58fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "ax.set_title('Task 2: Labeled Grids Inside Texas', fontsize=16)\n",
    "plot = masked_labels.plot(ax=ax, cmap='viridis', add_colorbar=True)\n",
    "plot.colorbar.set_label('Grid Cell ID', size=12)\n",
    "texas_shape.plot(ax=ax, facecolor='none', edgecolor='black', linewidth=2)\n",
    "\n",
    "ax.set_xlabel(\"Longitude\")\n",
    "ax.set_ylabel(\"Latitude\")\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50436be",
   "metadata": {},
   "source": [
    "### Verification that the grids are labelled as innstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6046c894",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_label_val = masked_labels.min().item()\n",
    "last_label_val = masked_labels.max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef32f63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_label_cell = masked_labels.where(masked_labels == first_label_val, drop=True)\n",
    "lat_1, lon_1 = first_label_cell.latitude.values[0], first_label_cell.longitude.values[0]\n",
    "\n",
    "last_label_cell = masked_labels.where(masked_labels == last_label_val, drop=True)\n",
    "lat_last, lon_last = last_label_cell.latitude.values[0], last_label_cell.longitude.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f16903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(12, 10))\n",
    "# plot = masked_labels.plot(ax=ax, cmap='viridis', add_colorbar=True)\n",
    "# plot.colorbar.set_label('Grid Cell ID', size=12)\n",
    "# texas_shape.plot(ax=ax, facecolor='none', edgecolor='black', linewidth=2)\n",
    "# ax.scatter(lon_1, lat_1, color='cyan', marker='*', s=300, edgecolor='black', linewidth=1.5,\n",
    "#            label=f'Min Label (Top-Left): {int(first_label_val)}')\n",
    "# ax.scatter(lon_last, lat_last, color='magenta', marker='X', s=300, edgecolor='white', linewidth=1.5,\n",
    "#            label=f'Max Label (Bottom-Right): {int(last_label_val)}')\n",
    "\n",
    "# ax.set_xlabel(\"Longitude\")\n",
    "# ax.set_ylabel(\"Latitude\")\n",
    "# ax.grid(True)\n",
    "# ax.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055cb6c7",
   "metadata": {},
   "source": [
    "### Task 3 : Change the spatial resolution from 800m to 50km. This requires keeping grid # 1, counting to grid # 51 and removing grids between 1 and 51. Repeat the same procedure all the way towards the last grid, which is grid # ~700,000. After that should have nearly 280 grids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefe858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample_factor = 63\n",
    "\n",
    "coarsened_labels = masked_labels.isel(\n",
    "    latitude=slice(0, None, downsample_factor),\n",
    "    longitude=slice(0, None, downsample_factor)\n",
    ")\n",
    "\n",
    "num_selected = int(coarsened_labels.notnull().sum().values)\n",
    "print(f\"Number of selected grids for Task 3: {num_selected}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799a0fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_lons, selected_lats = np.meshgrid(\n",
    "    coarsened_labels.longitude.values,\n",
    "    coarsened_labels.latitude.values\n",
    ")\n",
    "\n",
    "valid_mask = ~np.isnan(coarsened_labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fd7a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected_lons, selected_lats = np.meshgrid(\n",
    "#    coarsened_labels.longitude.values,\n",
    "#    coarsened_labels.latitude.values\n",
    "#)\n",
    "\n",
    "#valid_mask = ~np.\n",
    "# isnan(coarsened_labels.values)\n",
    "#print(valid_mask)#print(coarsened_labels.values)\n",
    "\n",
    "# 1. ساخت شبکه مختصات\n",
    "selected_lons, selected_lats = np.meshgrid(\n",
    "    coarsened_labels.longitude.values,\n",
    "    coarsened_labels.latitude.values)\n",
    "\n",
    "# 2. بررسی valid_mask\n",
    "valid_mask = ~np.isnan(coarsened_labels.values)\n",
    "print(f\"تعداد مقادیر معتبر: {np.sum(valid_mask)}\")\n",
    "\n",
    "# 3. فیلتر کردن داده‌های معتبر\n",
    "valid_lons = selected_lons[valid_mask]\n",
    "valid_lats = selected_lats[valid_mask]\n",
    "\n",
    "# 4. چاپ داده‌ها\n",
    "print(valid_lons[:10])  # اولین ۱۰ مقدار از longitude‌های معتبر\n",
    "print(valid_lats[:10])  # اولین ۱۰ مقدار از latitude‌های معتبر\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53d409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(12, 10))\n",
    "# texas_shape.plot(ax=ax, facecolor='lightgray', edgecolor='black', alpha=0.8)\n",
    "# ax.scatter(selected_lons[valid_mask], selected_lats[valid_mask], color='red', marker='o', s=35, label=f'{num_selected} Selected Grids')\n",
    "# ax.set_xlabel(\"Longitude\")\n",
    "# ax.set_ylabel(\"Latitude\")\n",
    "# ax.grid(True)\n",
    "# ax.legend()\n",
    "# ax.set_aspect('equal', adjustable='box')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bb13c2",
   "metadata": {},
   "source": [
    "### Task 4 : Precipitation data is hourly based. At all ~280 grids, sum precipitation data in each day to switch to daily-based data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7d8ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_ds = ds_texas.where(mask)\n",
    "labeled_ds['grid_label'] = label_da.where(mask)\n",
    "downsample_factor = 63\n",
    "\n",
    "ds_50km = labeled_ds.isel(\n",
    "    latitude=slice(0, None, downsample_factor),\n",
    "    longitude=slice(0, None, downsample_factor)\n",
    ")\n",
    "\n",
    "ds_50km = ds_50km.where(ds_50km['grid_label'].notnull(), drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc60b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_50km['APCP_surface']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2526f285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Task 3: Downsample AFTER clipping and masking ===\n",
    "\n",
    "lat_vals = ds_texas.latitude.values\n",
    "lon_vals = ds_texas.longitude.values\n",
    "\n",
    "# Texas grid downsampled to ~50 km\n",
    "selected_lats = lat_vals[::63]\n",
    "selected_lons = lon_vals[::63]\n",
    "\n",
    "selected_lons, selected_lats = np.meshgrid(selected_lons, selected_lats)\n",
    "\n",
    "print(\"Downsampled grid shape:\", selected_lats.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068b3a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_test = selected_lons.flat[50]\n",
    "lat_test = selected_lats.flat[50]\n",
    "\n",
    "pd = ds_texas.sel(longitude=lon_test, latitude=lat_test, method='nearest')\n",
    "print(\"Value:\", pd['TMP_2maboveground'].isel(time=0).values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207d82fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample the actual Texas dataset coordinates (1 km → ~50 km)\n",
    "ds_lat = ds_texas.latitude.values\n",
    "ds_lon = ds_texas.longitude.values\n",
    "\n",
    "# stride = 63\n",
    "lat_down = ds_lat[::63]\n",
    "lon_down = ds_lon[::63]\n",
    "\n",
    "# Build meshgrid\n",
    "selected_lons, selected_lats = np.meshgrid(lon_down, lat_down)\n",
    "\n",
    "print(\"Downsampled grid shape:\", selected_lats.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f967a08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_test = selected_lons.flat[50]\n",
    "lat_test = selected_lats.flat[50]\n",
    "\n",
    "value = ds_texas.sel(longitude=lon_test, latitude=lat_test, method='nearest')['TMP_2maboveground'].isel(time=0).values\n",
    "print(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d373d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lat = selected_lats[0, 0]   # first selected lat\n",
    "print(\"test_lat:\", test_lat)\n",
    "\n",
    "print(\"Is there any matching latitude?\",\n",
    "      np.isclose(test_lat, ds_texas.latitude.values).any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0886acd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lon = selected_lons[0, 0]\n",
    "print(\"test_lon:\", test_lon)\n",
    "\n",
    "print(\"Is there any matching longitude?\",\n",
    "      np.isclose(test_lon, ds_texas.longitude.values).any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5c81c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "tmp0 = ds_texas['TMP_2maboveground'].isel(time=0).values\n",
    "mask_valid = np.isfinite(tmp0)\n",
    "\n",
    "print(\"Percentage of valid temperature values:\",\n",
    "      100 * np.mean(mask_valid), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3d4f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp0 = ds_texas['TMP_2maboveground'].isel(time=0)\n",
    "valid_mask = np.isfinite(tmp0.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26fdab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_lat, valid_lon = np.where(valid_mask)\n",
    "\n",
    "# pick every Nth valid cell\n",
    "stride = len(valid_lat) // 280\n",
    "lat_idx = valid_lat[::stride]\n",
    "lon_idx = valid_lon[::stride]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f983692",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ds_texas['TMP_2maboveground'].isel(time=0,\n",
    "                                          latitude=lat_idx[10],\n",
    "                                          longitude=lon_idx[10]).values\n",
    "print(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6c986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp0 = ds_texas['TMP_2maboveground'].isel(time=0).values\n",
    "valid_mask = np.isfinite(tmp0)\n",
    "valid_lat_idx, valid_lon_idx = np.where(valid_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c6d410",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_lats = ds_texas.latitude.values[lat_idx]\n",
    "selected_lons = ds_texas.longitude.values[lon_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88e761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ds_texas['TMP_2maboveground'].isel(\n",
    "    time=0,\n",
    "    latitude=lat_idx[0],\n",
    "    longitude=lon_idx[0]\n",
    ").values\n",
    "print(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c486085",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_points = 280\n",
    "total_valid = len(valid_lat_idx)\n",
    "\n",
    "indices = np.linspace(0, total_valid - 1, target_points).astype(int)\n",
    "\n",
    "lat_idx = valid_lat_idx[indices]\n",
    "lon_idx = valid_lon_idx[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2cf60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_texas = ds_texas_bbox.rio.clip(texas_shape.geometry, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ce60f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_texas is already clipped to Texas exactly using rioxarray\n",
    "\n",
    "# Compute valid mask from temperature field\n",
    "tmp0 = ds_texas['TMP_2maboveground'].isel(time=0).values\n",
    "valid_mask = np.isfinite(tmp0)\n",
    "\n",
    "# Coordinates of valid gridcells\n",
    "valid_lat_idx, valid_lon_idx = np.where(valid_mask)\n",
    "\n",
    "# Compute stride to get ~280 points\n",
    "target_points = 280\n",
    "stride = max(1, len(valid_lat_idx) // target_points)\n",
    "\n",
    "# Downsample\n",
    "lat_idx = valid_lat_idx[::stride]\n",
    "lon_idx = valid_lon_idx[::stride]\n",
    "\n",
    "# Use indices to extract lat/lon\n",
    "selected_lats = ds_texas.latitude.values[lat_idx]\n",
    "selected_lons = ds_texas.longitude.values[lon_idx]\n",
    "\n",
    "# Meshgrid\n",
    "selected_lons, selected_lats = np.meshgrid(selected_lons, selected_lats)\n",
    "\n",
    "print(\"Selected grid shape:\", selected_lats.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7861b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ds_texas['TMP_2maboveground'].isel(\n",
    "    time=0,\n",
    "    latitude=lat_idx[5],\n",
    "    longitude=lon_idx[5]\n",
    ").values\n",
    "\n",
    "print(\"Temperature at a selected point:\", test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dd274a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp0 = ds_texas['TMP_2maboveground'].isel(time=0).values\n",
    "valid_mask = np.isfinite(tmp0)\n",
    "valid_lat_idx, valid_lon_idx = np.where(valid_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31121eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_points = 280\n",
    "total_valid = len(valid_lat_idx)\n",
    "\n",
    "indices = np.linspace(0, total_valid - 1, target_points).astype(int)\n",
    "\n",
    "lat_idx = valid_lat_idx[indices]\n",
    "lon_idx = valid_lon_idx[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e63998",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_lats = ds_texas.latitude.values[lat_idx]\n",
    "selected_lons = ds_texas.longitude.values[lon_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6d69ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ds_texas['TMP_2maboveground'].isel(\n",
    "    time=0,\n",
    "    latitude=lat_idx[0],\n",
    "    longitude=lon_idx[0]\n",
    ").values\n",
    "print(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6358e275",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp0 = ds_texas['TMP_2maboveground'].isel(time=0).values\n",
    "valid_pct = np.mean(np.isfinite(tmp0)) * 100\n",
    "print(\"Valid temperature %:\", valid_pct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d459ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp0 = ds_texas['TMP_2maboveground'].isel(time=0).values\n",
    "valid_mask = np.isfinite(tmp0)\n",
    "\n",
    "valid_lat_idx, valid_lon_idx = np.where(valid_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f27292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lat_idx and lon_idx already computed from valid_mask\n",
    "# These index pairs guarantee VALID temperature points\n",
    "selected_latitudes = ds_texas.latitude.values[lat_idx]\n",
    "selected_longitudes = ds_texas.longitude.values[lon_idx]\n",
    "\n",
    "output_file = f\"hourly_temperature_data_{Start_date}_{End_date}.csv\"\n",
    "batch_size = 10\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    f.write(\"longitude,latitude,datetime,temperature_K\\n\")\n",
    "\n",
    "total_records = 0\n",
    "\n",
    "for batch_start in range(0, len(lat_idx), batch_size):\n",
    "    batch_end = min(batch_start + batch_size, len(lat_idx))\n",
    "    \n",
    "    print(f\"Processing batch: {batch_start} to {batch_end-1}\")\n",
    "    \n",
    "    batch_records = 0\n",
    "    \n",
    "    for k in range(batch_start, batch_end):\n",
    "        \n",
    "        i = lat_idx[k]   # row index\n",
    "        j = lon_idx[k]   # column index\n",
    "        \n",
    "        lat_val = ds_texas.latitude.values[i]\n",
    "        lon_val = ds_texas.longitude.values[j]\n",
    "        \n",
    "        # extract full hourly timeseries using index-based selection\n",
    "        cell = ds_texas['TMP_2maboveground'].isel(latitude=i, longitude=j)\n",
    "        \n",
    "        # convert to pandas Series\n",
    "        series = cell.to_series()\n",
    "        \n",
    "        # write valid temperatures to file\n",
    "        with open(output_file, \"a\") as f:\n",
    "            for dt, temp in series.items():\n",
    "                if np.isnan(temp):\n",
    "                    continue\n",
    "                f.write(f\"{lon_val},{lat_val},{dt},{temp}\\n\")\n",
    "                batch_records += 1\n",
    "\n",
    "        print(f\"  Point #{k}: {batch_records} records added\")\n",
    "    \n",
    "    total_records += batch_records\n",
    "    print(f\"Batch complete: {batch_records} records (Total: {total_records})\")\n",
    "\n",
    "print(\"\\nDone! Temperature data saved to\", output_file)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "880f0921",
   "metadata": {},
   "source": [
    "### Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a57a4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== RESUME FROM POINT 154 ======\n",
    "resume_idx = 154  # <-- Change this number to resume from another point\n",
    "\n",
    "output_file = f\"hourly_temperature_data_{Start_date}_{End_date}.csv\"\n",
    "batch_size = 9\n",
    "\n",
    "# IMPORTANT:\n",
    "# Do NOT overwrite the file — append instead.\n",
    "# So open in append mode except for the header.\n",
    "# Remove the \"write header\" part.\n",
    "\n",
    "total_records = 0\n",
    "\n",
    "for batch_start in range(resume_idx, len(lat_idx), batch_size):\n",
    "    batch_end = min(batch_start + batch_size, len(lat_idx))\n",
    "    \n",
    "    print(f\"Processing batch: {batch_start} to {batch_end-1}\")\n",
    "    \n",
    "    batch_records = 0\n",
    "    \n",
    "    for k in range(batch_start, batch_end):\n",
    "        \n",
    "        # Skip points already processed last time\n",
    "        if k < resume_idx:\n",
    "            continue\n",
    "        \n",
    "        i = lat_idx[k]\n",
    "        j = lon_idx[k]\n",
    "\n",
    "        lat_val = ds_texas.latitude.values[i]\n",
    "        lon_val = ds_texas.longitude.values[j]\n",
    "        \n",
    "        cell = ds_texas['TMP_2maboveground'].isel(latitude=i, longitude=j)\n",
    "        series = cell.to_series()\n",
    "\n",
    "        # Append new data\n",
    "        with open(output_file, \"a\") as f:\n",
    "            for dt, temp in series.items():\n",
    "                if np.isnan(temp):\n",
    "                    continue\n",
    "                f.write(f\"{lon_val},{lat_val},{dt},{temp}\\n\")\n",
    "                batch_records += 1\n",
    "        \n",
    "        print(f\"  Point #{k}: {batch_records} records added\")\n",
    "    \n",
    "    total_records += batch_records\n",
    "    print(f\"Batch complete: {batch_records} records (Total: {total_records})\")\n",
    "\n",
    "print(\"\\nResume complete. New data appended to\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81bc2a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
